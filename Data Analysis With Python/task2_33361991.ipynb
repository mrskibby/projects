{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8tinZOUlDER"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "\n",
        "# FIT5196 Task 2 in Assessment 1\n",
        "    \n",
        "#### Student Name: Namzus Sakib\n",
        "#### Student ID: 33361991\n",
        "\n",
        "Date: 27th August 2023\n",
        "\n",
        "Environment: Python 3.9\n",
        "\n",
        "Libraries used:\n",
        "* os (for interacting with the operating system, included in Python xxxx)\n",
        "* pandas 1.1.0 (for dataframe, installed and imported)\n",
        "* multiprocessing (for performing processes on multi cores, included in Python 3.6.9 package)\n",
        "* itertools (for performing operations on iterables)\n",
        "* nltk 3.5 (Natural Language Toolkit, installed and imported)\n",
        "* nltk.collocations (for finding bigrams, installed and imported)\n",
        "* nltk.tokenize (for tokenization, installed and imported)\n",
        "* nltk.stem (for stemming the tokens, installed and imported)\n",
        "\n",
        "    </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnnLnFnLlDEU"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "## Table of Contents\n",
        "\n",
        "</div>\n",
        "\n",
        "[1. Introduction](#Intro) <br>\n",
        "[2. Importing Libraries](#libs) <br>\n",
        "[3. Examining Input File](#examine) <br>\n",
        "[4. Loading and Parsing Files](#load) <br>\n",
        "$\\;\\;\\;\\;$[4.1. Tokenization](#tokenize) <br>\n",
        "$\\;\\;\\;\\;$[4.2. Whatever else](#whetev) <br>\n",
        "$\\;\\;\\;\\;$[4.3. Finding First 200 Bigrams](#bigrams) <br>\n",
        "$\\;\\;\\;\\;$[4.4. Whatever else](#whetev1) <br>\n",
        "[5. Writing Output Files](#write) <br>\n",
        "$\\;\\;\\;\\;$[5.1. Vocabulary List](#write-vocab) <br>\n",
        "$\\;\\;\\;\\;$[5.2. Sparse Matrix](#write-sparseMat) <br>\n",
        "[6. Summary](#summary) <br>\n",
        "[7. References](#Ref) <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8mo6PPRlDEU"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "## 1.  Introduction  <a class=\"anchor\" name=\"Intro\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewZrff73lDEV"
      },
      "source": [
        "This assessment concerns textual data and the aim is to extract data, process them, and transform them into a proper format. The dataset provided is in the format of a PDF file containing ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSr_kwKclDEV"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "## 2.  Importing Libraries  <a class=\"anchor\" name=\"libs\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acwZw2NklDEW"
      },
      "source": [
        "In this assessment, any python packages is permitted to be used. The following packages were used to accomplish the related tasks:\n",
        "\n",
        "* **os:** to interact with the operating system, e.g. navigate through folders to read files\n",
        "* **re:** to define and use regular expressions\n",
        "* **pandas:** to work with dataframes\n",
        "* **multiprocessing:** to perform processes on multi cores for fast performance\n",
        "* ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qgmGWs8HlDEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83aed847-e33c-409e-ae08-a3be944bb42a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langid in /usr/local/lib/python3.10/dist-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from langid) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.1)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.0 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.0)\n",
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.23.5)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20221105)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.18.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install langid\n",
        "!pip install pandas PyPDF2\n",
        "!pip install PyMuPDF\n",
        "!pip install tabula-py\n",
        "!pip install requests beautifulsoup4\n",
        "!pip install pdfplumber\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter\n",
        "import pdfplumber\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tabula import read_pdf\n",
        "import fitz\n",
        "import PyPDF2\n",
        "import os\n",
        "import re\n",
        "import langid\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from itertools import chain\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import *\n",
        "from nltk.collocations import *\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import MWETokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.util import ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwNp0KnWlDEX"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "SA7fSJiRlDEY"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "## 3.  Examining Input File <a class=\"anchor\" name=\"examine\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "bPCuEl8smTHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd62b040-cdff-43ce-8ea4-564927ea35aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CJDLDI6lDEY"
      },
      "source": [
        "Let's examine what is the content of the file. For this purpose, the content will be read through file path and I have checked it before that it will contain 2 columns which are called id and download link respectively. After the file is read and stored in data_df dataframe, I will write in to csv file with the name 33361991_paper_list.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RyLbqkRxmCEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a5e027-3cd2-4b74-b5ef-2b0c882f8861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id                                      download_link\n",
            "0    5483  https://papers.nips.cc/paper_files/paper/2022/...\n",
            "1   10026  https://cdn.aaai.org/ojs/17611/17611-13-21105-...\n",
            "2    1969  https://papers.nips.cc/paper_files/paper/2021/...\n",
            "3    4055  https://papers.nips.cc/paper_files/paper/2021/...\n",
            "4    5086  https://papers.nips.cc/paper_files/paper/2022/...\n",
            "..    ...                                                ...\n",
            "75   9501  https://cdn.aaai.org/ojs/17098/17098-13-20592-...\n",
            "76    448  https://papers.nips.cc/paper_files/paper/2020/...\n",
            "77   7757  https://cdn.aaai.org/ojs/5722/5722-13-8947-1-1...\n",
            "78   9374  https://cdn.aaai.org/ojs/17021/17021-13-20515-...\n",
            "79   1098  https://papers.nips.cc/paper_files/paper/2020/...\n",
            "\n",
            "[80 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Path to the PDF file\n",
        "file_path = '/content/drive/Shareddrives/FIT5196_S2_2023/Assessment 1/student_data/task2/33361991_task2_input.pdf'\n",
        "\n",
        "# Extract tabular data from the PDF using tabula-py\n",
        "df_list = read_pdf(file_path, pages='all', multiple_tables=True)\n",
        "\n",
        "# Assuming the relevant table is the first one\n",
        "# If needed, you can iterate through df_list to identify the correct table\n",
        "data_df = df_list[0]\n",
        "\n",
        "# Rename columns to match your expected columns\n",
        "data_df.columns = ['id', 'download_link']\n",
        "\n",
        "# Display the DataFrame\n",
        "print(data_df)\n",
        "\n",
        "# Save the DataFrame to a CSV file named '33361991_paper_list.csv'\n",
        "data_df.to_csv('33361991_paper_list.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpDVyW4YlDEZ"
      },
      "source": [
        "It is noteiced that file contains id and links to the papers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7c1-c3olDEa"
      },
      "source": [
        "Having parsed the pdf file, the following observations can be made:\n",
        "1. The pdf has 80 rows and 2 columns which contains the IDs and the link to the research paper\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ENnHWjoXlDEc"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "## 4.  Loading and Parsing File <a class=\"anchor\" name=\"load\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9esGMx8lDEc"
      },
      "source": [
        "In this section, I have created a folder to store the downloaded research papers. And iterate through each of the download links to downlaod the pdf in the research_papers folder with the name as its id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "i0yElwywlDEa"
      },
      "outputs": [],
      "source": [
        "# Create a folder to save downloaded research papers\n",
        "output_folder = 'research_papers'\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "0SA37sl0lDEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c41a0fc-decb-491d-e45b-4cca2fb776e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 5483_paper.pdf\n",
            "Downloaded 10026_paper.pdf\n",
            "Downloaded 1969_paper.pdf\n",
            "Downloaded 4055_paper.pdf\n",
            "Downloaded 5086_paper.pdf\n",
            "Downloaded 956_paper.pdf\n",
            "Downloaded 8886_paper.pdf\n",
            "Downloaded 10675_paper.pdf\n",
            "Downloaded 10522_paper.pdf\n",
            "Downloaded 1672_paper.pdf\n",
            "Downloaded 7127_paper.pdf\n",
            "Downloaded 129_paper.pdf\n",
            "Downloaded 5445_paper.pdf\n",
            "Downloaded 477_paper.pdf\n",
            "Downloaded 2058_paper.pdf\n",
            "Downloaded 2409_paper.pdf\n",
            "Downloaded 4392_paper.pdf\n",
            "Downloaded 6916_paper.pdf\n",
            "Downloaded 4531_paper.pdf\n",
            "Downloaded 540_paper.pdf\n",
            "Downloaded 5922_paper.pdf\n",
            "Downloaded 8443_paper.pdf\n",
            "Downloaded 2278_paper.pdf\n",
            "Downloaded 679_paper.pdf\n",
            "Downloaded 5639_paper.pdf\n",
            "Downloaded 1808_paper.pdf\n",
            "Downloaded 9778_paper.pdf\n",
            "Downloaded 2613_paper.pdf\n",
            "Downloaded 1190_paper.pdf\n",
            "Downloaded 8817_paper.pdf\n",
            "Downloaded 1638_paper.pdf\n",
            "Downloaded 2715_paper.pdf\n",
            "Downloaded 5953_paper.pdf\n",
            "Downloaded 3177_paper.pdf\n",
            "Downloaded 8492_paper.pdf\n",
            "Downloaded 6048_paper.pdf\n",
            "Downloaded 4654_paper.pdf\n",
            "Downloaded 1006_paper.pdf\n",
            "Downloaded 10249_paper.pdf\n",
            "Downloaded 10190_paper.pdf\n",
            "Downloaded 1146_paper.pdf\n",
            "Downloaded 2727_paper.pdf\n",
            "Downloaded 4436_paper.pdf\n",
            "Downloaded 5161_paper.pdf\n",
            "Downloaded 2422_paper.pdf\n",
            "Downloaded 4198_paper.pdf\n",
            "Downloaded 6045_paper.pdf\n",
            "Downloaded 5765_paper.pdf\n",
            "Downloaded 5298_paper.pdf\n",
            "Downloaded 8180_paper.pdf\n",
            "Downloaded 9229_paper.pdf\n",
            "Downloaded 5752_paper.pdf\n",
            "Downloaded 8280_paper.pdf\n",
            "Downloaded 2229_paper.pdf\n",
            "Downloaded 9406_paper.pdf\n",
            "Downloaded 9214_paper.pdf\n",
            "Downloaded 10771_paper.pdf\n",
            "Downloaded 5831_paper.pdf\n",
            "Downloaded 9526_paper.pdf\n",
            "Downloaded 6982_paper.pdf\n",
            "Downloaded 584_paper.pdf\n",
            "Downloaded 849_paper.pdf\n",
            "Downloaded 2038_paper.pdf\n",
            "Downloaded 11310_paper.pdf\n",
            "Downloaded 6013_paper.pdf\n",
            "Downloaded 11315_paper.pdf\n",
            "Downloaded 3582_paper.pdf\n",
            "Downloaded 4097_paper.pdf\n",
            "Downloaded 9808_paper.pdf\n",
            "Downloaded 4368_paper.pdf\n",
            "Downloaded 9378_paper.pdf\n",
            "Downloaded 2712_paper.pdf\n",
            "Downloaded 10010_paper.pdf\n",
            "Downloaded 7694_paper.pdf\n",
            "Downloaded 1768_paper.pdf\n",
            "Downloaded 9501_paper.pdf\n",
            "Downloaded 448_paper.pdf\n",
            "Downloaded 7757_paper.pdf\n",
            "Downloaded 9374_paper.pdf\n",
            "Downloaded 1098_paper.pdf\n",
            "Download completed.\n"
          ]
        }
      ],
      "source": [
        "# Iterate through the DataFrame and download research papers\n",
        "for index, row in data_df.iterrows():\n",
        "    download_url = row['download_link']\n",
        "    paper_id = row['id']\n",
        "\n",
        "    response = requests.get(download_url)\n",
        "    paper_path = os.path.join(output_folder, f'{paper_id}_paper.pdf')\n",
        "\n",
        "    with open(paper_path, 'wb') as paper_file:\n",
        "        paper_file.write(response.content)\n",
        "\n",
        "    print(f\"Downloaded {paper_id}_paper.pdf\")\n",
        "\n",
        "print(\"Download completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uh9oUXAlDEd"
      },
      "source": [
        "How we can see that all 80 of the research papers are downloaded and saved in the research_papers folder.\n",
        "\n",
        "Now I will create an empty list abstract then iterate through all the papers to find the abstract part and store it in the abtract list. The abstract should be stored according to the id of the paper. The abstract will be extracted through the proper regex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "vUZuFeuQlDEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b32abb5-a11e-4322-9104-769c685bc961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id                                      download_link  \\\n",
            "0    5483  https://papers.nips.cc/paper_files/paper/2022/...   \n",
            "1   10026  https://cdn.aaai.org/ojs/17611/17611-13-21105-...   \n",
            "2    1969  https://papers.nips.cc/paper_files/paper/2021/...   \n",
            "3    4055  https://papers.nips.cc/paper_files/paper/2021/...   \n",
            "4    5086  https://papers.nips.cc/paper_files/paper/2022/...   \n",
            "..    ...                                                ...   \n",
            "75   9501  https://cdn.aaai.org/ojs/17098/17098-13-20592-...   \n",
            "76    448  https://papers.nips.cc/paper_files/paper/2020/...   \n",
            "77   7757  https://cdn.aaai.org/ojs/5722/5722-13-8947-1-1...   \n",
            "78   9374  https://cdn.aaai.org/ojs/17021/17021-13-20515-...   \n",
            "79   1098  https://papers.nips.cc/paper_files/paper/2020/...   \n",
            "\n",
            "                                             abstract  \n",
            "0   ThekernelMaximumMeanDiscrepancy(MMD)isapopular...  \n",
            "1   TheprogressinQuery-focusedMulti-DocumentSummar...  \n",
            "2   Perturb-and-MAPoffersanelegantapproachtoapprox...  \n",
            "3   Adversarial patch attacks that craft the pixel...  \n",
            "4   Reinforcementlearning(RL)inlonghorizonandspars...  \n",
            "..                                                ...  \n",
            "75  Withtherecentadvancesingraphneuralnetworks,the...  \n",
            "76  Westudyminimaxconvergenceratesofnonparametricd...  \n",
            "77  significantly advanced the state-of-the-art in...  \n",
            "78  query samples (i.e., query set) from the novel...  \n",
            "79  Physicalphenomenaintherealworldareoftendescrib...  \n",
            "\n",
            "[80 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Iterate through the downloaded papers and extract the 'Abstract'\n",
        "abstracts = []\n",
        "\n",
        "for index, row in data_df.iterrows():\n",
        "    paper_id = row['id']\n",
        "    paper_path = os.path.join(output_folder, f'{paper_id}_paper.pdf')\n",
        "\n",
        "    with pdfplumber.open(paper_path) as pdf:\n",
        "        # Extract text from the first page (you might need to adjust this)\n",
        "        first_page = pdf.pages[0]\n",
        "        text = first_page.extract_text()\n",
        "\n",
        "        # Extract the 'Abstract' section (you might need to adjust this)\n",
        "        abstract_match = re.search(r'\\bAbstract\\b(.+?)\\bIntroduction\\b', text, re.DOTALL)\n",
        "        if abstract_match:\n",
        "            abstract = abstract_match.group(1).strip()\n",
        "\n",
        "            # Split text by line breaks and join with a space\n",
        "            abstract = ' '.join(abstract.splitlines())\n",
        "\n",
        "            abstracts.append(abstract)\n",
        "        else:\n",
        "            abstracts.append(\"Abstract not found\")\n",
        "\n",
        "# Add the 'Abstract' column to the DataFrame\n",
        "data_df['abstract'] = abstracts\n",
        "\n",
        "# Display the DataFrame with 'Abstract' column\n",
        "print(data_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see that the abstracts are extracted in the abstract column of the dataframe and the abstracts are according to the ids of the paper.\n",
        "\n",
        "Now I will replace the ligatures, for now I have used the default but kept space for more if needed."
      ],
      "metadata": {
        "id": "WSsgIAwjLGm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_ligatures(text):\n",
        "    ligatures = {\n",
        "        'ﬁ': 'fi', 'ﬂ': 'fl', 'ﬀ': 'ff', 'ﬃ': 'ffi', 'ﬄ': 'ffl',\n",
        "        # Add more ligatures as needed\n",
        "    }\n",
        "\n",
        "    for ligature, replacement in ligatures.items():\n",
        "        text = text.replace(ligature, replacement)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "Vay4WHChllAw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will create a function for the replacement of the special characters in the text."
      ],
      "metadata": {
        "id": "gGUPx5VoLkcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_special_characters(text):\n",
        "    # Use appropriate replacements for special HTML entities\n",
        "    special_characters = {\n",
        "        '&amp;': '&',\n",
        "        '&lt;': '<',\n",
        "        '&gt;': '>',\n",
        "        # Add more special characters as needed\n",
        "    }\n",
        "\n",
        "    for entity, replacement in special_characters.items():\n",
        "        text = text.replace(entity, replacement)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "dM2w1IG0LhsR"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will create a function for the hyphenated words int he abstract column."
      ],
      "metadata": {
        "id": "t6Mcj6RvL1c7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_hyphenated_words(text):\n",
        "    # Replace hyphen-separated words\n",
        "    fixed_text = re.sub(r'(?<=\\w)-\\s*(?=\\w)', '', text)\n",
        "    return fixed_text"
      ],
      "metadata": {
        "id": "2yPHcNZVL2O_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will iterate through the abstract column and apply the replace_ligature, replace_special_characters and fix_hyphenated_words for each row and then display the data frame."
      ],
      "metadata": {
        "id": "xG2GdbapMKbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the 'Abstract' column and apply replacements\n",
        "data_df['abstract'] = data_df['abstract'].apply(replace_ligatures)\n",
        "data_df['abstract'] = data_df['abstract'].apply(replace_special_characters)\n",
        "data_df['abstract'] = data_df['abstract'].apply(fix_hyphenated_words)\n",
        "\n",
        "# Display the DataFrame with replaced 'Abstract'\n",
        "print(data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHOuGhZLMLI8",
        "outputId": "c1e6277e-b1c3-4afd-b500-63c0ad21625e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id                                      download_link  \\\n",
            "0    5483  https://papers.nips.cc/paper_files/paper/2022/...   \n",
            "1   10026  https://cdn.aaai.org/ojs/17611/17611-13-21105-...   \n",
            "2    1969  https://papers.nips.cc/paper_files/paper/2021/...   \n",
            "3    4055  https://papers.nips.cc/paper_files/paper/2021/...   \n",
            "4    5086  https://papers.nips.cc/paper_files/paper/2022/...   \n",
            "..    ...                                                ...   \n",
            "75   9501  https://cdn.aaai.org/ojs/17098/17098-13-20592-...   \n",
            "76    448  https://papers.nips.cc/paper_files/paper/2020/...   \n",
            "77   7757  https://cdn.aaai.org/ojs/5722/5722-13-8947-1-1...   \n",
            "78   9374  https://cdn.aaai.org/ojs/17021/17021-13-20515-...   \n",
            "79   1098  https://papers.nips.cc/paper_files/paper/2020/...   \n",
            "\n",
            "                                             abstract  \n",
            "0   ThekernelMaximumMeanDiscrepancy(MMD)isapopular...  \n",
            "1   TheprogressinQueryfocusedMultiDocumentSummariz...  \n",
            "2   PerturbandMAPoffersanelegantapproachtoapproxim...  \n",
            "3   Adversarial patch attacks that craft the pixel...  \n",
            "4   Reinforcementlearning(RL)inlonghorizonandspars...  \n",
            "..                                                ...  \n",
            "75  Withtherecentadvancesingraphneuralnetworks,the...  \n",
            "76  Westudyminimaxconvergenceratesofnonparametricd...  \n",
            "77  significantly advanced the stateoftheart in va...  \n",
            "78  query samples (i.e., query set) from the novel...  \n",
            "79  Physicalphenomenaintherealworldareoftendescrib...  \n",
            "\n",
            "[80 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "VIfQCD1VlDEe"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "### 4.1. Tokenization <a class=\"anchor\" name=\"tokenize\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gchByyjolDEf"
      },
      "source": [
        "Tokenization is a principal step in text processing and producing unigrams and bigrams. In this section, I have tokenized the abstract and also read the stopwords_en.txt which was provided to me in moodle.\n",
        "\n",
        "The tokenization was done using the regex:\n",
        "[A-Za-z]\\w+(?:[-'?]\\w+)?\n",
        "\n",
        "and also PorterStemmer is initialized\n",
        "\n",
        "Step 1 is the tokenization of the abstrcat column and step 2 is the removal of context-independent stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "p8zT4N0RlDEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465c08d0-b234-4f55-d196-dc484823820e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Load NLTK resources\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load stopwords_en.txt\n",
        "with open('stopwords_en.txt', 'r') as stopwords_file:\n",
        "    context_independent_stopwords = set(stopwords_file.read().splitlines())\n",
        "\n",
        "# Initialize the Porter stemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "# Tokenization regular expression\n",
        "token_pattern = r\"[A-Za-z]\\w+(?:[-'?]\\w+)?\"\n",
        "\n",
        "# Step 1: Tokenize using the regular expression\n",
        "def tokenize(text):\n",
        "    return re.findall(token_pattern, text.lower())\n",
        "\n",
        "data_df['tokens'] = data_df['abstract'].apply(tokenize)\n",
        "\n",
        "# Step 2: Remove context-independent stop words\n",
        "def remove_stopwords(tokens):\n",
        "    return [token for token in tokens if token not in context_independent_stopwords]\n",
        "\n",
        "data_df['tokens'] = data_df['tokens'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I display the data_df to see how it looks like."
      ],
      "metadata": {
        "id": "SYq4W5k_N50Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "b45bHR38qTko",
        "outputId": "880abca5-0da7-4d98-c01f-05b236f77249"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                      download_link  \\\n",
              "0    5483  https://papers.nips.cc/paper_files/paper/2022/...   \n",
              "1   10026  https://cdn.aaai.org/ojs/17611/17611-13-21105-...   \n",
              "2    1969  https://papers.nips.cc/paper_files/paper/2021/...   \n",
              "3    4055  https://papers.nips.cc/paper_files/paper/2021/...   \n",
              "4    5086  https://papers.nips.cc/paper_files/paper/2022/...   \n",
              "..    ...                                                ...   \n",
              "75   9501  https://cdn.aaai.org/ojs/17098/17098-13-20592-...   \n",
              "76    448  https://papers.nips.cc/paper_files/paper/2020/...   \n",
              "77   7757  https://cdn.aaai.org/ojs/5722/5722-13-8947-1-1...   \n",
              "78   9374  https://cdn.aaai.org/ojs/17021/17021-13-20515-...   \n",
              "79   1098  https://papers.nips.cc/paper_files/paper/2020/...   \n",
              "\n",
              "                                             abstract  \\\n",
              "0   ThekernelMaximumMeanDiscrepancy(MMD)isapopular...   \n",
              "1   TheprogressinQueryfocusedMultiDocumentSummariz...   \n",
              "2   PerturbandMAPoffersanelegantapproachtoapproxim...   \n",
              "3   Adversarial patch attacks that craft the pixel...   \n",
              "4   Reinforcementlearning(RL)inlonghorizonandspars...   \n",
              "..                                                ...   \n",
              "75  Withtherecentadvancesingraphneuralnetworks,the...   \n",
              "76  Westudyminimaxconvergenceratesofnonparametricd...   \n",
              "77  significantly advanced the stateoftheart in va...   \n",
              "78  query samples (i.e., query set) from the novel...   \n",
              "79  Physicalphenomenaintherealworldareoftendescrib...   \n",
              "\n",
              "                                               tokens  \n",
              "0   [thekernelmaximummeandiscrepancy, mmd, isapopu...  \n",
              "1   [theprogressinqueryfocusedmultidocumentsummari...  \n",
              "2   [perturbandmapoffersanelegantapproachtoapproxi...  \n",
              "3   [adversarial, patch, attacks, craft, pixels, c...  \n",
              "4   [reinforcementlearning, rl, inlonghorizonandsp...  \n",
              "..                                                ...  \n",
              "75  [withtherecentadvancesingraphneuralnetworks, t...  \n",
              "76  [westudyminimaxconvergenceratesofnonparametric...  \n",
              "77  [significantly, advanced, stateoftheart, lingu...  \n",
              "78  [query, samples, query, set, set, unseenclasse...  \n",
              "79  [physicalphenomenaintherealworldareoftendescri...  \n",
              "\n",
              "[80 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d22cef7-07b5-491c-ac71-03803797c548\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>download_link</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5483</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2022/...</td>\n",
              "      <td>ThekernelMaximumMeanDiscrepancy(MMD)isapopular...</td>\n",
              "      <td>[thekernelmaximummeandiscrepancy, mmd, isapopu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10026</td>\n",
              "      <td>https://cdn.aaai.org/ojs/17611/17611-13-21105-...</td>\n",
              "      <td>TheprogressinQueryfocusedMultiDocumentSummariz...</td>\n",
              "      <td>[theprogressinqueryfocusedmultidocumentsummari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1969</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2021/...</td>\n",
              "      <td>PerturbandMAPoffersanelegantapproachtoapproxim...</td>\n",
              "      <td>[perturbandmapoffersanelegantapproachtoapproxi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4055</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2021/...</td>\n",
              "      <td>Adversarial patch attacks that craft the pixel...</td>\n",
              "      <td>[adversarial, patch, attacks, craft, pixels, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5086</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2022/...</td>\n",
              "      <td>Reinforcementlearning(RL)inlonghorizonandspars...</td>\n",
              "      <td>[reinforcementlearning, rl, inlonghorizonandsp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>9501</td>\n",
              "      <td>https://cdn.aaai.org/ojs/17098/17098-13-20592-...</td>\n",
              "      <td>Withtherecentadvancesingraphneuralnetworks,the...</td>\n",
              "      <td>[withtherecentadvancesingraphneuralnetworks, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>448</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2020/...</td>\n",
              "      <td>Westudyminimaxconvergenceratesofnonparametricd...</td>\n",
              "      <td>[westudyminimaxconvergenceratesofnonparametric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>7757</td>\n",
              "      <td>https://cdn.aaai.org/ojs/5722/5722-13-8947-1-1...</td>\n",
              "      <td>significantly advanced the stateoftheart in va...</td>\n",
              "      <td>[significantly, advanced, stateoftheart, lingu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>9374</td>\n",
              "      <td>https://cdn.aaai.org/ojs/17021/17021-13-20515-...</td>\n",
              "      <td>query samples (i.e., query set) from the novel...</td>\n",
              "      <td>[query, samples, query, set, set, unseenclasse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1098</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2020/...</td>\n",
              "      <td>Physicalphenomenaintherealworldareoftendescrib...</td>\n",
              "      <td>[physicalphenomenaintherealworldareoftendescri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d22cef7-07b5-491c-ac71-03803797c548')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d22cef7-07b5-491c-ac71-03803797c548 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d22cef7-07b5-491c-ac71-03803797c548');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9fd982dc-83eb-4824-a52e-66ef5d657a21\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fd982dc-83eb-4824-a52e-66ef5d657a21')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9fd982dc-83eb-4824-a52e-66ef5d657a21 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NglwwiJRnPZd"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "### 4.2. Removal of rare tokens <a class=\"anchor\" name=\"whetev\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqZos1q6lDEf"
      },
      "source": [
        "Now we remove the rare tokens which apprear in less than 3% of the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "OPBNTTq6lDEg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "f7ae8fb5-6fd6-45f7-efd3-2ffbc4fae248"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                      download_link  \\\n",
              "0    5483  https://papers.nips.cc/paper_files/paper/2022/...   \n",
              "1   10026  https://cdn.aaai.org/ojs/17611/17611-13-21105-...   \n",
              "2    1969  https://papers.nips.cc/paper_files/paper/2021/...   \n",
              "3    4055  https://papers.nips.cc/paper_files/paper/2021/...   \n",
              "4    5086  https://papers.nips.cc/paper_files/paper/2022/...   \n",
              "..    ...                                                ...   \n",
              "75   9501  https://cdn.aaai.org/ojs/17098/17098-13-20592-...   \n",
              "76    448  https://papers.nips.cc/paper_files/paper/2020/...   \n",
              "77   7757  https://cdn.aaai.org/ojs/5722/5722-13-8947-1-1...   \n",
              "78   9374  https://cdn.aaai.org/ojs/17021/17021-13-20515-...   \n",
              "79   1098  https://papers.nips.cc/paper_files/paper/2020/...   \n",
              "\n",
              "                                             abstract  \\\n",
              "0   ThekernelMaximumMeanDiscrepancy(MMD)isapopular...   \n",
              "1   TheprogressinQueryfocusedMultiDocumentSummariz...   \n",
              "2   PerturbandMAPoffersanelegantapproachtoapproxim...   \n",
              "3   Adversarial patch attacks that craft the pixel...   \n",
              "4   Reinforcementlearning(RL)inlonghorizonandspars...   \n",
              "..                                                ...   \n",
              "75  Withtherecentadvancesingraphneuralnetworks,the...   \n",
              "76  Westudyminimaxconvergenceratesofnonparametricd...   \n",
              "77  significantly advanced the stateoftheart in va...   \n",
              "78  query samples (i.e., query set) from the novel...   \n",
              "79  Physicalphenomenaintherealworldareoftendescrib...   \n",
              "\n",
              "                                               tokens  \n",
              "0                                                  []  \n",
              "1                         [dataset, dataset, dataset]  \n",
              "2                                                  []  \n",
              "3                                                  []  \n",
              "4                                                  []  \n",
              "..                                                ...  \n",
              "75  [chair, person, chair, person, umbrella, dinin...  \n",
              "76                                                 []  \n",
              "77  [stateoftheart, tasks, al, stateoftheart, mode...  \n",
              "78  [samples, set, set, samples, al, set, al, al, ...  \n",
              "79                                                 []  \n",
              "\n",
              "[80 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e4738ea-fe74-48fc-a825-bff98f88791e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>download_link</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5483</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2022/...</td>\n",
              "      <td>ThekernelMaximumMeanDiscrepancy(MMD)isapopular...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10026</td>\n",
              "      <td>https://cdn.aaai.org/ojs/17611/17611-13-21105-...</td>\n",
              "      <td>TheprogressinQueryfocusedMultiDocumentSummariz...</td>\n",
              "      <td>[dataset, dataset, dataset]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1969</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2021/...</td>\n",
              "      <td>PerturbandMAPoffersanelegantapproachtoapproxim...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4055</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2021/...</td>\n",
              "      <td>Adversarial patch attacks that craft the pixel...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5086</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2022/...</td>\n",
              "      <td>Reinforcementlearning(RL)inlonghorizonandspars...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>9501</td>\n",
              "      <td>https://cdn.aaai.org/ojs/17098/17098-13-20592-...</td>\n",
              "      <td>Withtherecentadvancesingraphneuralnetworks,the...</td>\n",
              "      <td>[chair, person, chair, person, umbrella, dinin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>448</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2020/...</td>\n",
              "      <td>Westudyminimaxconvergenceratesofnonparametricd...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>7757</td>\n",
              "      <td>https://cdn.aaai.org/ojs/5722/5722-13-8947-1-1...</td>\n",
              "      <td>significantly advanced the stateoftheart in va...</td>\n",
              "      <td>[stateoftheart, tasks, al, stateoftheart, mode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>9374</td>\n",
              "      <td>https://cdn.aaai.org/ojs/17021/17021-13-20515-...</td>\n",
              "      <td>query samples (i.e., query set) from the novel...</td>\n",
              "      <td>[samples, set, set, samples, al, set, al, al, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1098</td>\n",
              "      <td>https://papers.nips.cc/paper_files/paper/2020/...</td>\n",
              "      <td>Physicalphenomenaintherealworldareoftendescrib...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e4738ea-fe74-48fc-a825-bff98f88791e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e4738ea-fe74-48fc-a825-bff98f88791e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e4738ea-fe74-48fc-a825-bff98f88791e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83dc8279-2f31-4a1b-ab6e-0e0efefabe6f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83dc8279-2f31-4a1b-ab6e-0e0efefabe6f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83dc8279-2f31-4a1b-ab6e-0e0efefabe6f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Remove rare tokens (appearing in less than 3% of the files)\n",
        "def remove_rare_tokens(tokens, frequency_threshold=0.03):\n",
        "    total_docs = len(data_df)\n",
        "    token_counter = Counter(tokens)\n",
        "\n",
        "    return [token for token in tokens if token_counter[token] / total_docs >= frequency_threshold]\n",
        "\n",
        "data_df['tokens'] = data_df['tokens'].apply(remove_rare_tokens)\n",
        "\n",
        "data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section calculates the frequency of tokens and bigrams, and then removes context-dependent stop words (both unigrams and bigrams) based on the appearance frequency threshold of 95% or more using the stemmed tokens.\n",
        "\n",
        "Also uses token_counter to store the final tokens which are less than 3 characters or symbols.\n",
        "\n",
        "Final the final_tokens are sorted"
      ],
      "metadata": {
        "id": "natLF4SFO0-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_list = []\n",
        "\n",
        "for tokens in data_df['tokens']:\n",
        "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens if len(token) >= 3]\n",
        "    vocab_list.extend(stemmed_tokens)\n",
        "\n",
        "# Calculate token and bigram frequencies\n",
        "token_counter = Counter(vocab_list)\n",
        "all_bigrams = [bigram for tokens in data_df['tokens'] for bigram in ngrams(tokens, 2)]\n",
        "bigram_counter = Counter(all_bigrams)\n",
        "\n",
        "# Calculate the threshold for context-dependent stop words\n",
        "doc_count_threshold = int(len(data_df) * 0.95)\n",
        "\n",
        "# Remove context-dependent stop words\n",
        "final_tokens = []\n",
        "\n",
        "for token in token_counter:\n",
        "    if token_counter[token] < doc_count_threshold and len(token) >= 3:\n",
        "        final_tokens.append(token)\n",
        "\n",
        "for bigram in bigram_counter:\n",
        "    if bigram_counter[bigram] < doc_count_threshold:\n",
        "        # Convert the bigram tuple to a string\n",
        "        bigram_str = ' '.join(bigram)\n",
        "        final_tokens.append(bigram_str)\n",
        "\n",
        "# Sort and remove duplicates from final_tokens\n",
        "final_tokens = sorted(set(final_tokens))"
      ],
      "metadata": {
        "id": "3OoQ34-r2oy_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVqFfwwMlDEg"
      },
      "source": [
        "At this stage, all reviews for each PID are tokenized and are stored as a value in the new dictionary (separetely for each day).\n",
        "\n",
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Ve6IZ2I-lDEg"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "### 4.3. Generate numerical representation<a class=\"anchor\" name=\"bigrams\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGhUY2UlDEg"
      },
      "source": [
        "One of the tasks is to generate the numerical representation for all tokens in abstract."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "sgFFtm6qlDEg"
      },
      "outputs": [],
      "source": [
        "# Create a mapping of token to index\n",
        "token_to_index = {token: index for index, token in enumerate(final_tokens)}\n",
        "\n",
        "# Generate the sparse numerical representation using CountVectorizer\n",
        "vectorizer = CountVectorizer(vocabulary=token_to_index, tokenizer=lambda x: x.split())\n",
        "sparse_representation = vectorizer.transform(data_df['abstract'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cbSKT6PlDEg"
      },
      "source": [
        "the CountVectorizer from scikit-learn is used to generate the sparse numerical representation of the token frequencies. The token_to_index mapping ensures that the tokens are mapped to their respective indices, as generated in step 3. The resulting sparse representation is then output to the countvec.txt file as per the specified format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO1PJO-dlDEh"
      },
      "source": [
        "At this stage, we have a dictionary of tokenized words.\n",
        "\n",
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmaGJYIJlDEl"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "## 5. Writing Output Files <a class=\"anchor\" name=\"write\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjMBqRetlDEl"
      },
      "source": [
        "files need to be generated:\n",
        "* Vocabulary list\n",
        "* Sparse matrix (count_vectors)\n",
        "\n",
        "This is performed in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc6tQ4ljlDEm"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "### 5.1. Vocabulary List <a class=\"anchor\" name=\"write-vocab\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDlbpGYilDEm"
      },
      "source": [
        "List of vocabulary should also be written to a file, sorted alphabetically, with their reference codes in front of them. This file also refers to the sparse matrix in the next file. For this purpose, ....."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Y6OUXHlxlDEm"
      },
      "outputs": [],
      "source": [
        "# Generate and save vocab.txt\n",
        "with open('33361991_vocab.txt', 'w') as vocab_file:\n",
        "    for index, token in enumerate(final_tokens):\n",
        "        vocab_file.write(f\"{token}: {index}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkGH81YFlDEn"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "### 5.2. Sparse Matrix <a class=\"anchor\" name=\"write-sparseMat\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtxqUAwmlDEn"
      },
      "source": [
        "For writing sparse matrix for a paper, we firstly calculate the frequency of words for that paper.\n",
        "The token frequencies for each paper are calculated and stored in the paper_token_frequencies dictionary. The resulting sparse numerical representation is then output to the 33361991_countvec.txt file as per the specified format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "__n1fdIqlDEn"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty dictionary to store token frequencies per paper\n",
        "paper_token_frequencies = {}\n",
        "\n",
        "# Iterate through papers and calculate token frequencies\n",
        "for index, row in data_df.iterrows():\n",
        "    paper_tokens = row['tokens']\n",
        "    token_frequencies = Counter(paper_tokens)\n",
        "    paper_token_frequencies[row['id']] = token_frequencies\n",
        "\n",
        "# Write the sparse numerical representation to countvec.txt\n",
        "with open('33361991_countvec.txt', 'w') as countvec_file:\n",
        "    for paper_id, token_freqs in paper_token_frequencies.items():\n",
        "        token_indices_and_frequencies = [\n",
        "            f\"{token_to_index[token]}:{frequency}\"\n",
        "            for token, frequency in token_freqs.items()\n",
        "            if token in token_to_index\n",
        "        ]\n",
        "        countvec_file.write(f\"{paper_id}, {' '.join(token_indices_and_frequencies)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUFQU-QXlDEn"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWjri6x_lDEn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "## 6. Summary <a class=\"anchor\" name=\"summary\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXAprlSblDEn"
      },
      "source": [
        "Here's a summary of the entire process from top to bottom:\n",
        "\n",
        "1. **Import Libraries**:\n",
        "\n",
        "  Import necessary libraries such as os, re, nltk, sklearn, and others for data manipulation, text processing, and generating sparse representations.\n",
        "\n",
        "2. **Load DataFrame**:\n",
        "\n",
        "  Load your DataFrame containing 'id' and 'abstract' columns that store paper IDs and abstract texts.\n",
        "\n",
        "3. **Load NLTK Resource**s:\n",
        "\n",
        "  Download NLTK resources like stopwords using nltk.download('stopwords').\n",
        "\n",
        "4. **Load Stopwords**:\n",
        "\n",
        "  Load a list of context-independent stopwords from a file named 'stopwords_en.txt'.\n",
        "\n",
        "5. **Initialize Stemmer**:\n",
        "\n",
        "  Initialize a Porter stemmer for stemming tokens.\n",
        "\n",
        "6. **Tokenization**:\n",
        "\n",
        "  Tokenize abstract texts using a regular expression pattern and store the tokens in the DataFrame.\n",
        "\n",
        "7. **Remove Context-Independent Stopwords**:\n",
        "\n",
        "  Remove context-independent stopwords from the tokenized abstracts.\n",
        "\n",
        "8. **Remove Rare Tokens**:\n",
        "\n",
        "  Remove tokens that appear in less than 3% of the papers.\n",
        "\n",
        "9. **Preprocessing Steps**:\n",
        "\n",
        "  Implement and apply additional preprocessing steps, including steps like stemming, removing context-dependent stopwords, removing short tokens, and more.\n",
        "\n",
        "10. **Generate Vocabulary**:\n",
        "\n",
        "  Generate a vocabulary list based on the processed tokens, considering various preprocessing steps.\n",
        "\n",
        "11. **Create Token-to-Index Mapping**:\n",
        "\n",
        "  Create a mapping of tokens to their corresponding indices in the vocabulary.\n",
        "\n",
        "12. **Calculate Token Frequencies**:\n",
        "\n",
        "  Calculate token frequencies for each paper and store them in a dictionary.\n",
        "\n",
        "13. **Generate Sparse Numerical Representation**:\n",
        "\n",
        "  Use CountVectorizer from scikit-learn to generate a sparse numerical representation of token frequencies.\n",
        "\n",
        "14. **Output Sparse Representation**:\n",
        "\n",
        "  Write the sparse numerical representation to a file named 'countvec.txt', including paper IDs and token frequencies in the specified format.\n",
        "\n",
        "**Summary**:\n",
        "\n",
        "The entire process involves loading the data, performing text preprocessing steps, generating sparse representations, and outputting the results to files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFXYKxO8lDEn"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HppxDtWNlDEn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "## 7. References <a class=\"anchor\" name=\"Ref\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCkWr-M1lDEo"
      },
      "source": [
        "[1] Pandas dataframe.drop_duplicates(), https://www.geeksforgeeks.org/python-pandas-dataframe-drop_duplicates/, Accessed 13/08/2022.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9O-a1UlDEo"
      },
      "source": [
        "## --------------------------------------------------------------------------------------------------------------------------"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}